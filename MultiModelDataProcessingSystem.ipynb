{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharook-khan-pathan/MultiModelDataProcessingSystem/blob/main/MultiModelDataProcessingSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3sPS2d8rCHN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Step 1 ‚Äì Sentence Transformers\n",
        "!pip install sentence-transformers\n",
        "\n",
        "#Step 2 ‚Äì ChromaDB\n",
        "!pip install chromadb\n",
        "\n",
        "#Step 3 ‚Äì Gemini API\n",
        "!pip install google-generativeai\n",
        "\n",
        "#Step 4 ‚Äì PDF support\n",
        "!pip install PyPDF2\n",
        "\n",
        "#Step 5 ‚Äì DOCX support\n",
        "!pip install python-docx\n",
        "\n",
        "#Step 6 ‚Äì PPTX support\n",
        "!pip install python-pptx\n",
        "\n",
        "#Step 7 ‚Äì YouTube downloader\n",
        "!pip install pytube\n",
        "\n",
        "#Step 8 ‚Äì Speech recognition\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "#Step 9 ‚Äì Video/audio processing\n",
        "!pip install moviepy\n",
        "\n",
        "#Step 10 ‚Äì Image processing\n",
        "!pip install Pillow\n",
        "\n",
        "#Step 11 ‚Äì OCR (text from images)\n",
        "!pip install pytesseract\n",
        "\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6mb6RpmyqBV"
      },
      "outputs": [],
      "source": [
        "!pip install -U pytube\n",
        "!pip install -q yt-dlp pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHDb7mBHrs9L"
      },
      "outputs": [],
      "source": [
        "# Step 1: Imports\n",
        "# ======================================================\n",
        "import os, tempfile\n",
        "from google.colab import files\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "import PyPDF2, docx\n",
        "from pptx import Presentation\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import yt_dlp\n",
        "import google.generativeai as genai\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC_qAjdqryzR"
      },
      "outputs": [],
      "source": [
        "#Step 2: Configure Gemini API\n",
        "# ======================================================\n",
        "import os\n",
        "\n",
        "api_key = os.environ.get(\"GENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"Set GENAI_API_KEY environment variable before running this notebook.\")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOfBXI6Ar-6s"
      },
      "outputs": [],
      "source": [
        "# Step 3: Initialize local embedding model\n",
        "# ======================================================\n",
        "# This model converts text into vector embeddings for ChromaDB memory\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40TFJvCxsEQS",
        "outputId": "f25bf4f8-808d-4f77-a4d9-a4286422ca1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Deleted previous memory collection.\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Initialize ChromaDB collection\n",
        "# ======================================================\n",
        "# ChromaDB stores embeddings + documents (memory system)\n",
        "client = chromadb.Client(Settings(persist_directory=\"./vector_store\"))\n",
        "collection_name = \"gemini_memory\"\n",
        "\n",
        "try:\n",
        "    client.delete_collection(collection_name)\n",
        "    print(\"‚úÖ Deleted previous memory collection.\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è No previous memory collection found to delete.\")\n",
        "\n",
        "collection = client.get_or_create_collection(collection_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwLtN81Ak6vQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OAel5kDbDfkT"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, chunk_size=500):\n",
        "    \"\"\"Splits text into smaller chunks\"\"\"\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "def extract_text_from_file(filename):\n",
        "    text = \"\"\n",
        "    ext = filename.split('.')[-1].lower()\n",
        "\n",
        "    try:\n",
        "        if ext in [\"txt\", \"md\"]:\n",
        "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "\n",
        "        elif ext == \"pdf\":\n",
        "            reader = PyPDF2.PdfReader(filename)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"\n",
        "\n",
        "        elif ext == \"docx\":\n",
        "            doc = docx.Document(filename)\n",
        "            for para in doc.paragraphs:\n",
        "                text += para.text + \"\\n\"\n",
        "\n",
        "        elif ext == \"pptx\":\n",
        "            prs = Presentation(filename)\n",
        "            for slide in prs.slides:\n",
        "                for shape in slide.shapes:\n",
        "                    if hasattr(shape, \"text\"):\n",
        "                        text += shape.text + \"\\n\"\n",
        "\n",
        "        elif ext in [\"png\", \"jpg\", \"jpeg\"]:\n",
        "            image = Image.open(filename)\n",
        "            text = pytesseract.image_to_string(image)\n",
        "\n",
        "        elif ext in [\"mp3\", \"wav\", \"mp4\"]:\n",
        "            audio_file = filename\n",
        "            if ext == \"mp4\":\n",
        "                from moviepy.editor import VideoFileClip\n",
        "                clip = VideoFileClip(filename)\n",
        "                temp_wav = \"temp_audio.wav\"\n",
        "                clip.audio.write_audiofile(temp_wav, codec='pcm_s16le')\n",
        "                clip.close()\n",
        "                audio_file = temp_wav\n",
        "            elif ext == \"mp3\":\n",
        "                temp_wav = \"temp_audio.wav\"\n",
        "                AudioSegment.from_file(filename).export(temp_wav, format=\"wav\")\n",
        "                audio_file = temp_wav\n",
        "\n",
        "            r = sr.Recognizer()\n",
        "            try:\n",
        "                with sr.AudioFile(audio_file) as source:\n",
        "                    audio = r.record(source)\n",
        "                    text = r.recognize_google(audio)\n",
        "            except Exception as e:\n",
        "                text = \"\"\n",
        "            if os.path.exists(audio_file):\n",
        "                os.remove(audio_file)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error extracting {filename}: {e}\")\n",
        "\n",
        "    return text\n",
        "\n",
        "def extract_text_from_youtube(url):\n",
        "    try:\n",
        "        url = url.split(\"?\")[0]  # clean URL\n",
        "        print(f\"üé• Downloading audio from: {url}\")\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".%(ext)s\").name\n",
        "\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'outtmpl': temp_file,\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            downloaded_path = ydl.prepare_filename(info)\n",
        "\n",
        "        wav_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n",
        "        audio = AudioSegment.from_file(downloaded_path)\n",
        "        os.remove(downloaded_path)\n",
        "\n",
        "        r = sr.Recognizer()\n",
        "        text = \"\"\n",
        "        chunk_length_ms = 60000  # 1 minute chunks\n",
        "        for i in range(0, len(audio), chunk_length_ms):\n",
        "            chunk = audio[i:i + chunk_length_ms]\n",
        "            chunk_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n",
        "            chunk.export(chunk_path, format=\"wav\")\n",
        "            with sr.AudioFile(chunk_path) as source:\n",
        "                audio_chunk = r.record(source)\n",
        "            try:\n",
        "                text += r.recognize_google(audio_chunk) + \" \"\n",
        "            except:\n",
        "                pass\n",
        "            os.remove(chunk_path)\n",
        "\n",
        "        if text.strip() == \"\":\n",
        "            print(\"‚ö†Ô∏è Transcription failed or empty.\")\n",
        "        else:\n",
        "            print(\"‚úÖ YouTube audio processed successfully!\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing YouTube video: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def store_text_in_chroma(text, prefix=\"file\"):\n",
        "    if not text.strip():\n",
        "        return 0\n",
        "    chunks = chunk_text(text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        embedding = embedder.encode(chunk).tolist()\n",
        "        collection.add(\n",
        "            ids=[f\"{prefix}_chunk_{i+1}\"],\n",
        "            embeddings=[embedding],\n",
        "            documents=[chunk]\n",
        "        )\n",
        "    return len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V3aaiYgscM3"
      },
      "outputs": [],
      "source": [
        "# Step 7: Store uploaded files automatically into ChromaDB\n",
        "# ======================================================\n",
        "\n",
        "# 1Ô∏è‚É£ Upload files via Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    text = extract_text_from_file(filename)\n",
        "    n_chunks = store_text_in_chroma(text, prefix=filename)\n",
        "    if n_chunks > 0:\n",
        "        print(f\"‚úÖ Stored {n_chunks} chunks from {filename}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è No valid text found in {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w21_9_ewxjYC"
      },
      "outputs": [],
      "source": [
        "youtube_url = input(\"üé• Enter YouTube URL (or press Enter to skip): \").strip()\n",
        "if youtube_url:\n",
        "    yt_text = extract_text_from_youtube(youtube_url)\n",
        "    n_chunks = store_text_in_chroma(yt_text, prefix=\"youtube\")\n",
        "    if n_chunks > 0:\n",
        "        print(f\"‚úÖ Stored {n_chunks} chunks from YouTube video\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No valid text from YouTube video\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgevgbG6smpF"
      },
      "outputs": [],
      "source": [
        "# Step 8: Interactive query function\n",
        "# ======================================================\n",
        "def query_memory_local(question: str):\n",
        "    query_embedding = embedder.encode(question).tolist()\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=3)\n",
        "\n",
        "    if not results[\"documents\"] or all(not d.strip() for d in results[\"documents\"][0]):\n",
        "        print(\"‚ö†Ô∏è No relevant information found in memory.\")\n",
        "        return\n",
        "\n",
        "    context = \" \".join([d for d in results[\"documents\"][0] if d.strip()])\n",
        "    prompt = f\"\"\"\n",
        "Use the following stored information to answer the question accurately.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "    response = gemini_model.generate_content(prompt)\n",
        "    print(\"ü§ñ Answer:\", response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwoh8vNXsr2K"
      },
      "outputs": [],
      "source": [
        "# Step 9: Interactive query loop\n",
        "# ======================================================\n",
        "while True:\n",
        "    question = input(\"\\nEnter your question (or type 'exit' to quit): \")\n",
        "    if question.lower() == \"exit\":\n",
        "        print(\"üëã Exiting AI memory system.\")\n",
        "        break\n",
        "    query_memory_local(question)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}